## DL на новостном графе

# Построение графа новостей
Вершинами в графе являются новости, представленные ссылкой на новость и текстом. Для подачи вершин в модель, было решено использовать предобученный текстовый енкодер, который кодирует каждую вершину как вектор размерности 312. Это решает сразу две проблемы: во-первых, можно быстро получить представление вершины, не обучая модель с нуля, во-вторых, такой подход позволит применять модель на новых данных, которых не было в обучении. В качестве модели для кодирования текстов была выбрана модель rubert-tiny2.  В тексте новости могут упоминаться другие новости в виде ссылок на них. Чтобы построить новостной граф, проведём рёбра от новости, в которой упоминались другие, к новостям, которые упоминаются в первой. После предобработки удалось собрать граф из 2240 рёбер и 7351 вершин. В изначальном датасете было около 16000 рёбер, но большая часть из них вела на источники, не представленные в выборке.

# Какие задачи решались

- Node classification - классификация новостей по тематикам:
    - общие новости
    - Энергетика
    - Финансовый сектор
    - Потребительские товары и услуги
    - Информационные технологии
    - Сырьевая промышленность
    - Машиностроение и транспорт
    - Происшествия

- Link prediction - предсказания наличия связи между новостями

# Предобработка данных
- Удаление дублей
- Удаление лишних ребёр (тех, которые ведут к новостям, не представленным в датасете)
- Выбор тегов новостей для использования в моделях и их кодирование перед подачей в модель

# Node Classification

Были выбраны самые частотные теги новостей. Слишком большое количество классов привело бы к плохому качеству, так как и примеров на каждый класс было бы мало.
После предобработки данных остался граф из 311 рёбер и 3630 вершин. К сожалению, большинство ребёр были связаны с новостями, относящимися к другим тегам.

Для решения задачи рассматривались две модели: простая линейная модель, никак не использующая информацию о соседях вершин, так и графовая нейронная сеть, аггрегирующая представления соседей для пересчёта ембеддинга вершин. Сравнивались два вида графовых сверток: обычная графовая свертка (graph convolution network) и свертка с вниманием (graph attention network). В графовых нейросетях после слоёв свертки используются те же слои, что и в простом подходе. Данные были разбиты на тренировочные, валидационные и тестовые по вершинам в соотношении 0.8/0.1/0.1 от общего числа вершин.

# Link Prediction

Для предсказания наличия связи использовались существующие ребра между новостями и насемплированные негативные ребра, которые в графе отсутствуют. Постановка задачи - бинарная классификация. Для связанных вершин хотим предсказывать число, близкое к 1, к для несвязанных - близкое к 0. Для получения представления двух вершин будем использовать поэлементное умножение умножение ембеддингов двух вершин. Для решения задачи также рассматривались две модели: первая получает представление двух вершин как поэлементное произведение ембеддингов из текстового енкодера и прогоняет вектор через линейную сеть. Вторая модель пересчитывает исходные признаки вершин через графовую свертку, считает представление двух вершин и полученный вектор прогоняет через линейную сеть, состоящую из тех же слоёв, что из бейзлайн. Для разбиения данных ребра графа были разбиты на тренировочные, валидационные и тестовые ребра. На трейне есть только тренировочные ребра, на валидации и тесте - есть ребра из обучения, которые используются для определения наличия связи между узлами, однако все метрики считаются только на тестовых или валидационных ребрах. Также были насемплированы негативные ребра, которых на самом деле нет в графе. Они были разбиты точно так же на тренирочные, валидационные и тестовые данные

# Результаты

| Эксперимент   | Node classification (acc) |Link prediction (acc)|
| ------------- | --------------------------|---------------      |
| baseline      | 0.7410                    | 0.8348              |
| GCNConv       | 0.7134                    | 0.9821              |
| GATConv       | 0.7272                    | 0.9642              |

# Выводы
В задаче классификации вершин не удалось побить бейзлайн, что скорее всего связано с ничтожно малым числом рёбер в графе, что вредит обучению, а не помогает решить задачу. В задаче link prediction графовая модель показала себя лучше, и в этом задаче ребёр было значительно больше, чем в предыдущем. По метрикам можно сделать вывод, что задачу предсказания связи между двумя новостями мы умеем решать